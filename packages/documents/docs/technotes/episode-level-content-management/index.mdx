---
sidebar_position: 2
---


import SequenceStructure from './images/sequence-structure.svg';

# TN9002: Episode Level Content Management: Act Player and Episode Core

## Abstract

**Act Player** and **Episode Core** are the core component to manage multiple
contents that creator made. In this article, we'll introduce the anatomy of
these parts and give a brief guide about how customizing your player for both
visual experience and functions which can fit your very own requirement.

## Introduction

Each episode is constructed with several *assets* (or *contents*, *segments*, 
they are the same concept but we use different word under different context),
asset could be a video or a small interactive program (Act Point), these assets
are arranged into a *sequence*, *Act Player* and *Core Manager* will play these
*assets* one by one.

### Episode Core

Episode Core is the fundenmental part which can manage all content segments
provided by creators, it will handle the following tasks:

* **Lifecycle Management:** To ensure contents loads smoothly and does not crash
due to memory spikes, we need a well-established lifecycle mechanism to schedule
the preloading, loading and destroy task of each part of your content, we will
how lifecycle works later.

* **Time synchronize and schedule:**
[Synchronizing multiple media source](https://github.com/recative/recative-system/blob/05a199e188eecf9b10cbb0225a478463d0a878d7/packages/time-schedule/src/timeline.ts) like
video channel and audio channel;
[triggering events](https://github.com/recative/recative-system/blob/05a199e188eecf9b10cbb0225a478463d0a878d7/packages/definitions/src/utils/managedCoreState.ts#L183)
for various purpose like displaying subtitles, showing additional tips at
specific time point of the video, switching BGM at different time, etc.

* **Audio playback management:** To make sure autoplay related functions can
work correctly, we built a time system which can handle all tasks related to
audio playback with the
[Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API).
This can help us play any audio files after users triggered their first
interaction with the page on any browser.

:::info
For video files, we split the file into two different parts: a video file and 
an audio file. There's an extension can handle this task in *Recative Studio*,
after the file is imported, channel splitting, compatibility fixing and many
other tasks can be finished automatically.
:::

* **Resource management:** Core Manager will manage all files imported to 
*Recative Studio* (like audio, video, subtitle files or texture files). It will
preload necessary resources, automatically select different resource for
different language and platform, select resource from multiple CDN and storage
source (which make offline storage possible).

* **Task queue:** Since JavaScript is a single-threaded language, we must design
a scheduling mechanism to ensure that a large number of background tasks will 
not affect the rendering performance. *Core Manager* provides priority queues:
the fast queue and the slow queue. You can arrange tasks into different queues
according to the priority of the tasks. *Core Manager* will arrange the tasks
without affecting rendering performance.

### Act Player

Act player implemented a React binding of Episode Core, it implemented all user
interfaces of the player, and built a bridge from your asset to the episode
core.

Act player provided a build-in interface implementation, which provides:

* **Loading Indicator:** This component will be shown if the metadata or content
is not loaded, or the buffer of the video have drained.

* **Subtitle:** This will show subtitle of your video content or audio clip
inside the act point program.

* **Dialog Component:** That show additional information on the right side of
your content, it looks like the information card of YouTube, but can display
more type of information, like texture, and audio.

 * **Controller:** Pause and play, setting content language, volume, navigating
to different assets and time, and more fundenmental elements for a player.

* **Stage:** All assets are placed inside the stage, it will create and destory
React Elements for different contents, and connect these contents with
*Core Manager*.

## Essential parts of a player

The interface components implemented above are default official implementation
of the player, developers can pass their own 
[interface component implementation](/api/act-player/interface/IUnmanagedActPointProps#interfaceComponents)
into the player and customize the visual experience and functionality of the
player. All interface components are React components, they are stored in an
array, they will be rendered in the player container.

### Building a interface component

We have to make the component met specific
[typing signiture](/api/act-player#InterfaceExtensionComponent) to make sure
*Core Manager* and *Act Player* can communicate with the component
implementation, basically, we will pass two parameters: 

* **`core`:** A instance of the *Episode Core*, we can use this parameter to
control most behavior of the player.

* **`loadingComponent`:** A component that indicate something is still loading,
you can show this component if something is stilling being cooked.

After the component is created, we can start to interact with the *Episode Core*.

### Different type of interface components

There're different type of interface components, you can choose one based on
your technical requirement.

* **Naïve components:** If we don't need let the *Episode Core* to control
the lifecycle of the component, this component is a naïve component, we don't
need to do anything special.

* **Managed components:** Managed components hooked up with the life cycle
management process of the *Episode Core*,
[component functions](/api/core-manager/interface/ComponentFunctions). Here are
some use cases:
  * **A play button layer:** if the media playback was paused, ask core
    call the `pause` function we provided via `componentFunctions`. When the
    function was called, we show the large "play" button.
  * **A transition animation layer:** show an animation while switching between
    assets above the player, which can hide the underlying resource loading
    process. we use `shouldBlockContentSwitch` life cycle to notify the
    *Episode Core* that all lifecycles should be processed manually, then we
    call `unblockAssetSetup` while the "ease-in" animation was played, then call
    `unblockAssetPlay` when the "ease-out" animation was played. For more
    details, see "Switching between contents" section below.

* **Critical components:** Critical components must be registered before or the
  player won't process any incoming requests. There is currently only one
  critical component called `stage`. Critical component could be naïve or
  managed.

:::info
Stage will show all assets available in an episode. The stage component should
implement methods that create, destroy, show, hide content in its 
`ComponentFunctions`, for more detail, checkout the
[source code](https://github.com/recative/recative-system/blob/master/packages/act-player/src/components/Stage/Stage.tsx).

Assets inside the stage components are implemented by *asset instance components*
like [videos](https://github.com/recative/recative-system/blob/master/packages/act-player/src/components/Stage/ActPoint.tsx)
and [act points](https://github.com/recative/recative-system/blob/master/packages/act-player/src/components/Stage/ActPoint.tsx).
The API for both of them is quite similar to that of *interface components*, but
we do not support third-party interface components implementations.
:::

### Subscribing Data from Episode Core

NanoStore

## Anatomy of Episode Core



### `Content` and `ContentInstance`

Content is the internal type used to describe the specification of content, which means a video, an interactive program or something else. When the Core needs to play content, it creates a `ContentInstance` from the Content, and asks the stage component to create the user interface side of it.

The ContentInstance contains all the resources it needs to play the content, and manages the lifecycle of the playback progress of the content.

ContentInstance holds some resources to be used by the Content. This includes:
- The `Timeline`, which coordinates the time of different tracks, like the RemoteTrack that represents the time of the user interface counterpart, and the AudioTrack below.
- The `AudioTrack`, which plays the audio track of a video. The `Timeline` will synchronize the time of the user interface counterpart (like the video element) to the `AudioTrack` if it has audio to play.
  - Backend: `@recative/audio-station`, `@recative/phonograph`. 
- The `AudioHost`, which plays sound effects for the interactive program.
- The `SubsequenceManager`, which allows the interactive program to create and control subsequences. For more information, see the Subsequence section below.
- The `managedCoreStateList`, which manages subtitles and other states in the content.

The `ContentInstance` also keeps references to some global resources, like the `TaskQueue`, which schedules async tasks around the Core.

### Lifecycle

The `ContentInstance` has 5 different states:
- idle, which means the `ContentInstance` is created, but it is not usable since the user interface counterpart is not created yet.
- preloading, which means the `ContentInstance` is created and its user interface counterpart is loading the required resources so it's not ready to show.
- ready, which means the `ContentInstance` is ready to be shown to the user.
- destroying(not present in the current version), which means the `ContentInstance` is destroying itself. This state will be used once we have the async destroying support
- destroyed, which means the `ContentInstance` is completely destroyed, all the resources it used are released.

`ContentInstance` also can be shown or hidden, which is independent of the states above. However, in practice, the `ContentInstance` should not be shown to the user when its state is not ready.

### `Sequence` and Subsequence

The Sequence is a sequence of Content. Contents in Sequence are also called segments, since they are parts of the sequence. It controls creation, destruction, showing and hiding of ContentInstance, switching process between the contents, calculation of time and process.

### Time calculation

Every segment in the Sequence has a duration. Some segments do not have a meaningful duration (like an interactive program), their duration should be infinite.

The Sequence does not keep track of time itself. It only manages which segment is playing. To know the time of the sequence, we just add up all the finite duration of played segments, and then add the time from the Timeline of the current segment if its duration is finite. To seek a specific time in the sequence, we find the segment that the time falls in, and calculate the time in that segment.

#### Switching between contents

Content switching is the most complicated part in Sequence. It manages seeking, transition between Contents in normal playback and starting of the first Content.

To start the internal process of Content switching, set the nextSegment to the order of the next Content, set nextSegmentStartTime to the start time of next Content after switching, then all the internal `switchToNextContent` method.

The `switchToNextContent` method will first get the blocker of this content switching. After that, it will wait for the blocker to unblock new content setup. When there are no more blockers for the new content setup, it will destroy old content if old content has the `earlyDestroyOnSwitch` property, and then create the new content.

After the creation of the new content, it will wait for the ready of new content, the blocker to unblock final switching, and dependency of the content to complete. After that, it will show the new content, destroy the old content if it is not destroyed, then set the time and playing state on the new content. If the next content does not have `preloadDisabled`, it will be preloaded at this position.

The starting of the first content also uses the Content switching process. However, the sequence is already switching when it is constructed.

Also, it is possible to switch from or switch to undefined content. When the sequence switches to undefined content, it will fire an 'end' event.

### Subsequence

<SequenceStructure
  style={{
      maxWidth: "200px",
      padding: '0 16px',
      float: "right",
  }}
  alt="The three level model of the Recative System"
/>

It's possible for `Content`s (especially interactive programs) to create subsequences. The subsequence is nearly the same as the main sequence, but some aspects of the subsequence are affected by the parent sequence. The subsequence will be completely hidden if its parent content is hidden. Also, it won't play if its parent content is not playing. The subsequence should also be destroyed when its parent content is destroyed.

There is a limited set of API for the user interface counterpart to create and control the subsequences, like how the player controls the main sequence directly from Core.